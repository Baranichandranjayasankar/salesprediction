# -*- coding: utf-8 -*-
"""Copy of salesprediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FnSOqIlaJ-1-10U236x85pjKbKFYJyPh
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

import matplotlib.pyplot as plt
import seaborn as sns

sp = pd.read_csv('/content/sales prediction.zip')

sp.head()

sp.tail()

sp.info()

sp.describe()

sp.isnull().sum()

sp.shape

sp.columns.values.tolist()

sns.displot(sp['Newspaper'])

iqr = sp.Newspaper.quantile(0.75) - sp.Newspaper.quantile(0.25)

lower_bridge = sp['Newspaper'].quantile(0.25) - (iqr*1.5)
upper_bridge = sp['Newspaper'].quantile(0.75) + (iqr*1.5)
print(lower_bridge)
print(upper_bridge)

data = sp.copy()

data.loc[data['Newspaper']>=93,'Newspaper'] = 93

sns.boxplot(data['Newspaper'])

sns.boxplot(data['Sales']);

sns.pairplot(data,x_vars=['TV','Newspaper','Radio'], y_vars='Sales',height=4,aspect=1,kind='scatter')
plt.show()

!pip install matplotlib --upgrade
import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(data.corr(), cmap="YlGnBu", annot=True) # Changed 'ylGnBu' to 'YlGnBu'
plt.show()

important_features = list(data.corr()['Sales'][ (data.corr()['Sales'] > 0.5) | (data.corr()['Sales'] < -0.5) ].index)
print(important_features)

x = data['TV']
y = data['Sales']

print(x.shape,y.shape)

import sklearn
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,)

print(x_train.shape)

print(y_train.shape)

print(x_test.shape)

print(y_test.shape)

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.model_selection import cross_val_score,GridSearchCV
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

knn = KNeighborsRegressor().fit(x_train.values.reshape(-1, 1),y_train) # Reshape x_train to a 2D array
knn_train_pred = knn.predict(x_train.values.reshape(-1, 1)) # Reshape x_train to a 2D array
knn_test_pred = knn.predict(x_test.values.reshape(-1, 1)) # Reshape x_test to a 2D array

print(knn_train_pred,knn_test_pred)

result = pd.DataFrame(columns=["Model", "Train R2", "Test R2","Train RMSE","Varianice"])

r2 = r2_score(y_test, knn_test_pred)
r2_train = r2_score(y_train, knn_train_pred)
rmse = np.sqrt(mean_squared_error(y_test, knn_test_pred))
variance = r2_train - r2

# Use pd.concat to concatenate the dictionary to the DataFrame.
result = pd.concat([result, pd.DataFrame({"Model": "KNN", "Train R2": r2_train, "Test R2": r2,"Train RMSE":rmse,"Varianice":variance}, index=[0])], ignore_index=True)

print("R2: ", r2)
print("RMSE: ", rmse)

result.head()

svr = SVR().fit(x_train.values.reshape(-1, 1),y_train)
svr

import statsmodels.api as sm

x_train_constant = sm.add_constant(x_train)
x_train_constant

model = sm.OLS(y_train, x_train_constant).fit()
model.summary()

plt.scatter(x_train, y_train)
plt.plot(x_train, model.predict(), color='red')
plt.title('Sales vs TV')
plt.xlabel('TV')
plt.ylabel('Sales')
plt.show()

y_train_pred = model.predict(x_train_constant)
res =(y_train - y_train_pred)
res

y_train_pred

fig = plt.figure()
sns.distplot(res, bins=20)
fig.suptitle('Error Terms', fontsize=15)
plt.xlabel('Errors', fontsize=15)
plt.show()

plt.scatter(x_train, res)
plt.show()

x_test_constant = sm.add_constant(x_test)
y_pred = model.predict(x_test_constant)

y_pred

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

np.sqrt(mean_squared_error(y_test, y_pred))

r2 = r2_score(y_test, y_pred)
r2

plt.scatter(x_test, y_test)
plt.plot(x_test, model.predict(sm.add_constant(x_test)), 'y') # add_constant is used to add a constant to the x_test array to make it compatible with the model.
plt.show()